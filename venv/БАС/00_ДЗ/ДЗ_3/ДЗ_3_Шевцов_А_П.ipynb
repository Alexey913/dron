{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f9de3a",
   "metadata": {},
   "source": [
    "# Домашнее задание: Работа с свёрточными нейронными сетями на PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b6468b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для работы с работой установим следующие библиотеки\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d648303",
   "metadata": {},
   "source": [
    "## Задание 1: Операции с матрицами (свёртка)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a7276",
   "metadata": {},
   "source": [
    "__В этом задании вам нужно будет реализовать свёртку (convolution) вручную с помощью\n",
    "матричных операций в PyTorch. Это поможет лучше понять, как работают свёрточные\n",
    "фильтры.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6bae4c",
   "metadata": {},
   "source": [
    "### 1. Создайте случайную матрицу (изображение) размером 5x5 и фильтр (ядро свёртки) размером 3x3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f108f51c",
   "metadata": {},
   "source": [
    "__Случайная матрица 5х5__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f1ee85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.randint(0, 256, size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6d785cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[218, 237, 255, 157,  94],\n",
       "       [143,  50,  18, 156, 128],\n",
       "       [173,  61, 137, 101, 131],\n",
       "       [106,  30, 123,  36, 240],\n",
       "       [ 35,  86,  85, 242,  46]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60679a",
   "metadata": {},
   "source": [
    "__В качестве фильтра создаем следующую матрицу__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3248f285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1.,  0.],\n",
       "       [-1.,  5., -1.],\n",
       "       [ 0., -1.,  0.]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.zeros((3,3))\n",
    "kernel[1, 1] = 5\n",
    "kernel[0, 1] = kernel[1, 0] = kernel[1, 2] = kernel[2, 1] = -1\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d0226978-1f4a-4420-94c3-0645efe08ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.empty([3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af60abc",
   "metadata": {},
   "source": [
    "### 2. Реализуйте функцию для выполнения свёртки изображения с этим фильтром. Напишите свёртку с шагом 1 и без использования встроенных функций PyTorch для свёртки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bbe3dbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-209., -508.,  376.],\n",
       "       [ -85.,  382.,   45.],\n",
       "       [-226.,  327., -526.]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv(img: np.ndarray, kernel: np.ndarray, stride: int=1) -> np.ndarray:\n",
    "    # т.к. в данной функции учитываем только шаг фильтра,\n",
    "    #то формулы размеров выходной матрицы равны:\n",
    "    h_in = img.shape[0]\n",
    "    w_in = img.shape[1]\n",
    "    h_out = int(((h_in - (kernel.shape[0] - 1) - 1) / stride) + 1)\n",
    "    w_out = int(((w_in - (kernel.shape[1] - 1) - 1) / stride) + 1)\n",
    "    # Создаем пустой массив для свертки, размером, определнным выше\n",
    "    out = np.empty([h_out, w_out])\n",
    "    # Проходим ядром по матрице\n",
    "    for i in range(h_out):\n",
    "        for j in range(w_out):\n",
    "            out[i, j] = np.sum(kernel * img[i:h_out+i, j:w_out+j])\n",
    "\n",
    "# 0\n",
    "#     0 - out[0,0] - img[0:3, 0:3]\n",
    "#     1 - out[0,1] - img[0:3, 1:4]\n",
    "#     2 - out[0,2] - img[0:3, 2:5]\n",
    "# 1\n",
    "#     0 - out[1,0] - img[1:4, 0:3]\n",
    "#     1 - out[1,1] - img[1:4, 1:4]\n",
    "#     2 - out[1,2] - img[1:4, 2:5]\n",
    "# 2\n",
    "#     0 - out[1,0] - img[2:5, 0:3]\n",
    "#     1 - out[1,1] - img[2:5, 1:4]\n",
    "#     2 - out[1,2] - img[2:5, 2:5]\n",
    "    \n",
    "    return out\n",
    "conv(img, kernel, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020caad6-12a2-4666-99ec-b6c9b8378cd9",
   "metadata": {},
   "source": [
    "### 3. Проверьте работу вашей функции, сравнив результат с использованием встроенной функции torch.nn.functional.conv2d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd23ac-a125-42a2-87cb-f9e54f725653",
   "metadata": {},
   "source": [
    "Для использования функции torch.nn.functional.conv2d необходимо преобразовать матрицы входа и ядра в тензоры. Для этого используем функцию reshape, где зададим количествовходных и выходных каналов, равными 1, а рзмеры тензоров, равными размерами матриц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "51944456",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_t = Tensor(img).reshape(1, 1, img.shape[0], img.shape[1])\n",
    "in_w = Tensor(kernel).reshape(1, 1, kernel.shape[0], kernel.shape[1])\n",
    "out_torch = F.conv2d(in_t, in_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "46c16692-19a3-4aa1-8013-0dc9e41ca3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-209., -508.,  376.],\n",
       "          [ -85.,  382.,   45.],\n",
       "          [-226.,  327., -526.]]]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e7915-faf6-4f8e-ad0e-2e87a8cede1e",
   "metadata": {},
   "source": [
    "__Как видно, результаты написанной функции и результаты подстановки в функцию torch.nn.functional.conv2d совпадают.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194ab24-7bb9-4a2e-9971-fdb2644a2ccd",
   "metadata": {},
   "source": [
    "## Задание 2: Настройка количества параметров между слоями свёртки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5cacc5-cd0a-4dd7-a196-0f9cf9429690",
   "metadata": {},
   "source": [
    "__Во втором задании вам нужно создать простую свёрточную нейронную сеть с несколькими слоями и настроить количество фильтров (параметров) между слоями свёртки, а также применить паддинг (padding), чтобы избежать уменьшения размерности данных.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d23596-ee0e-4016-8842-2ed4828e264e",
   "metadata": {},
   "source": [
    "### Создайте модель с двумя свёрточными слоями с использованием torch.nn.Conv2d.\n",
    "* Первый свёрточный слой должен содержать 16 фильтров, второй — 32 фильтра.\n",
    "* Для сохранения размерности используйте паддинг 1.\n",
    "* После свёрточных слоёв добавьте слой выравнивания (flatten) и полносвязный слой (fully connected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2fed5abc-559c-4110-8389-6e341d42172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MODEL, self).__init__()\n",
    "        # сверточные слои\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, padding=1, kernel_size=3),\n",
    "            nn.Conv2d(16, 32, padding=1, kernel_size=3),\n",
    "        )\n",
    "        # слой выравнивания\n",
    "        self.flatten_layer =  nn.Sequential(\n",
    "            nn.Flatten())\n",
    "        # полносвязный слой - зададим количество классов, равным 2, размеры тензора, равными размеру матрицы, т.к. используем padding=1\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(32 * img.shape[0] * img.shape[1], 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1a03d-4afc-4d57-ba03-107d9737a55d",
   "metadata": {},
   "source": [
    "__Использование модели__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "009bef90-2e45-40a1-9e9f-ac8a73bef545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.2007, 16.2408]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MODEL()\n",
    "print(model(in_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d74de23-ff4d-403d-8f84-7089f712d3ca",
   "metadata": {},
   "source": [
    "## Задание 3: Использование различных шагов и паддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab666e3-e41f-460b-89ae-5aca3f543866",
   "metadata": {},
   "source": [
    "В этом задании вам предстоит поэкспериментировать с различными значениями шага (stride) и паддинга (padding), а также объяснить, как они влияют на выходные размеры слоёв свёртки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36f03f5-535e-4b2e-b49d-f9ad36fd6651",
   "metadata": {},
   "source": [
    "### 1. Создайте три свёрточных слоя, каждый из которых будет использовать разные значения шага и паддинга:\n",
    "* Первый слой с шагом 1 и паддингом 1.\n",
    "* Второй слой с шагом 2 и без паддинга.\n",
    "* Третий слой с шагом 2 и паддингом 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58162e75-f48d-4ba4-a4a9-29e1154ac3d8",
   "metadata": {},
   "source": [
    "Количество фильтров для наглядности берем 2, чтобы получить компактный вывод тензора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba8d8b-4254-4cdb-8821-6e8dd984d020",
   "metadata": {},
   "source": [
    "__Первый слой с шагом 1 и паддингом 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3484c1cd-2a40-4446-aa68-711d26907fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1 = nn.Conv2d(1, 2, stride=1, padding=1, kernel_size=3)\n",
    "conv_out_1 = conv_1(in_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9533c5c4-0ffa-4580-9eab-51a76fc7988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 4.8881e+01,  4.2643e+01,  5.6469e+01,  7.3015e+01,  4.9126e+01],\n",
       "          [ 5.0440e+01,  7.6963e+01,  5.2033e+01,  7.8471e+01,  5.5196e+01],\n",
       "          [ 1.8074e+01,  5.0482e+01,  7.5947e+01,  4.6839e+01,  6.4992e+01],\n",
       "          [ 6.0351e-01,  7.2211e+01,  6.2750e+01,  8.2630e+01,  3.2562e+01],\n",
       "          [-1.7876e+01,  3.9372e+01, -1.2620e+01,  8.1229e+01, -3.2039e+01]],\n",
       "\n",
       "         [[ 4.5890e+01, -1.3271e+01, -6.0293e+01, -1.6543e+01, -3.7983e+00],\n",
       "          [-3.9119e+01, -1.2956e+02, -4.0449e+01, -6.6419e+01, -6.7681e+01],\n",
       "          [-1.8935e+01, -3.8248e+01, -3.3595e+01, -3.0621e+01, -3.3319e+01],\n",
       "          [-3.1095e+01, -4.8353e+01, -3.3929e+01,  3.5921e+01, -7.1848e+01],\n",
       "          [-1.2206e-01, -6.8562e+01, -1.6611e+00, -1.6418e+02, -8.5494e+01]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270fe70-9fa3-487d-a3a6-8c1ab533af87",
   "metadata": {},
   "source": [
    "__Второй слой с шагом 2 и без паддинга__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7e1817cb-9942-43b6-ac60-96e410d69a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2 = nn.Conv2d(1, 2, stride=2, padding=0, kernel_size=3)\n",
    "conv_out_2 = conv_2(in_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3f3e5aa6-3831-491c-8f3a-e1a631aca717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 87.6905,  42.5465],\n",
       "          [ 77.3349,  62.5965]],\n",
       "\n",
       "         [[176.0463,  90.9090],\n",
       "          [107.7828, 107.9515]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5350c8b-7a8b-4a40-83ff-1f4e0e592b8d",
   "metadata": {},
   "source": [
    "__Третий слой с шагом 2 и паддингом 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "86728194-c093-48db-849e-3e6eec7ffdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3 = nn.Conv2d(1, 2, stride=2, padding=2, kernel_size=3)\n",
    "conv_out_3 = conv_3(in_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e8e38d35-c4a3-4030-bf87-b67ae34b2806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -18.5900,   87.7835,   83.0492,   15.6753],\n",
       "          [ -11.0188,  187.7864,   59.7333,   47.1579],\n",
       "          [   2.3548,   53.4834,   88.6277,   55.0275],\n",
       "          [   8.0414,   46.9016,   87.1116,   -0.2006]],\n",
       "\n",
       "         [[ -26.8952, -119.1813,  -95.0545,  -21.6799],\n",
       "          [ -66.4907,  -85.1178,  -30.0258,  -45.3721],\n",
       "          [ -39.5898,  -57.2589, -104.8246,  -44.8756],\n",
       "          [  -5.1875,   -2.7383,   18.1179,    5.2139]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1688e5-9b37-4dd2-82fb-db84bad8b43d",
   "metadata": {},
   "source": [
    "### 2. Для каждого слоя выведите размерность выходных данных и объясните, как шаг и паддинг влияют на размер изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9c212165-ccd2-46f5-90bc-e31d3efdb02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 5, 5])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер свертки первого слоя (шаг=1, паддинг=1)\n",
    "conv_out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "069559d6-eb6b-4930-aee1-e4ae357d2cff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 2])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер свертки второго слоя (шаг=2, без паддинга)\n",
    "conv_out_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f99535ff-0da4-421a-8009-34753ce0e33b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4, 4])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер свертки третьего слоя (шаг=2, паддинг=2)\n",
    "conv_out_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3eca8-eb80-4204-a47e-67540678abcc",
   "metadata": {},
   "source": [
    "Расчет размера свертки также можно произвести методами Python, используя формулу вычисления размера свертки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "980cb945-a637-454f-acff-23595b45e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_calc(data, k, p, d, s):\n",
    "    \n",
    "    '''\n",
    "    data - размерность входного тензора\n",
    "    k - размер ядра [int, int]\n",
    "    p - паддинг [int, int]\n",
    "    d - расширение [int, int] (используются значения по умолчанию в torch - (1, 1))\n",
    "    s - шаг ядра [int, int] (используются значения по умолчанию в torch - (1, 1))\n",
    "    '''\n",
    "    \n",
    "    h_out = ((data[0] + 2 * p - d[0] * (k[0] - 1) - 1) / s[0]) + 1\n",
    "    w_out = ((data[1] + 2 * p - d[1] * (k[1] - 1) - 1) / s[1]) + 1\n",
    "    \n",
    "    return (int(h_out), int(w_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7a2720d5-5d74-4936-a86a-ea1247bc13f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер свертки 1-го слоя (5, 5)\n"
     ]
    }
   ],
   "source": [
    "# для первого слоя (шаг=1, паддинг=1)\n",
    "p = 1\n",
    "d = (1, 1)\n",
    "s = (1, 1)\n",
    "print(f'Размер свертки 1-го слоя {conv_calc(img.shape, kernel.shape, p, d, s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6cb8c446-41ee-4c5a-a20c-11d87585a3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер свертки 1-го слоя (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# для второго слоя (шаг=2, без паддинга)\n",
    "p = 0\n",
    "d = (1, 1)\n",
    "s = (2, 2)\n",
    "print(f'Размер свертки 1-го слоя {conv_calc(img.shape, kernel.shape, p, d, s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "de983e43-66cf-46fe-87c7-6153aae266f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер свертки 1-го слоя (4, 4)\n"
     ]
    }
   ],
   "source": [
    "# для третьего слоя (шаг=2, паддинг=2)\n",
    "p = 2\n",
    "d = (1, 1)\n",
    "s = (2, 2)\n",
    "print(f'Размер свертки 1-го слоя {conv_calc(img.shape, kernel.shape, p, d, s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad5ccce-925e-45c9-b6c5-4034946d9b5e",
   "metadata": {},
   "source": [
    "__Задание: После выполнения задания опишите, как каждый слой меняет размерность данных, и каким образом влияют параметры шагов и паддингов__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e870f-bcd5-4392-998b-24828729f76d",
   "metadata": {},
   "source": [
    "__Слой 1__ - не меняет размерность данных, то есть шаг=1 и паддинг=1 как бы нивелируют друг друга.\n",
    "\n",
    "__Слой 2__ - паддинг отсутствует, соответственно, размерность данных уменьшается, а шаг=2 ускоряет этот процесс.\n",
    "\n",
    "__Слой 3__ - шаг=2, как в предыдущем слое значительно сокращает размерность данных, однако паддинг=2 ее увеличивает.\n",
    "\n",
    "Из проведенных исследованийи формулы, реализованной в функции conv_calc, можне заключить следующее:\n",
    "1. Паддинг (p): одна единица паддинга увеличивает тензор в ширину и высоту на 2 единицы (при шаге=1; если шаг больше 1, то увеличение размерности условно можно принять как удвоенное отношение паддинга к шагу).\n",
    "2. Шаг (s): увеличение шага приводит к уменьшению выходного тензора. Размерность выходных данных условно в s раз меньше, чем входных (т.к. в формуле подсчета размерности присутствует +1 в самом конце)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826977d-958b-480f-84bf-5f41dbebb029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
